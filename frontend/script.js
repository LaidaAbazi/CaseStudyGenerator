// script.js â€” UPDATED VERSION with real-time transcript capture + farewell detection + fixed user + AI transcription

let peerConnection, dataChannel, isSessionReady = false;
const transcriptLog = []; // Log conversation { speaker, text }
let sessionTimeout;
let userBuffer = "";
let aiBuffer = "";
let hasEnded = false;

const audioElement = document.getElementById("aiAudio");
const startButton = document.getElementById("startBtn");
const statusEl = document.getElementById("status");

const systemInstructions = `
INSTRUCTIONS:
You are an emotionally intelligent, curious, slightly witty AI interviewer. You must behave like a real human podcast host: warm, reactive, professional-yet-casual. You are conducting a natural, voice-based conversation to gather a compelling story that can be turned into a case study. Do not act like a chatbot. Do not read a list. Sound like a human.

STYLE:
- Tone: Warm, conversational, emotionally intelligent,funny,focused,good listener,supportive.
- Use short, real-sounding reactions like: â€œNice,â€ â€œGot it,â€ â€œThatâ€™s clever,â€ â€œInterestingâ€¦â€
- Use casual expressions when appropriate: â€œOof,â€ â€œWow,â€ â€œThatâ€™s wild,â€ â€œHah, love that.â€
- Do not over-explain yourself. Never say â€œAs an AI...â€
- Use slight humor or wit if the moment allows â€” make the user smile
- Do not read instructions aloud

[INTRODUCTION_FLOW]

- Begin the conversation like a real human hopping onto a spontaneous voice call â€” unscripted, casual, warm.
- Use varied, natural greetings. Do not reuse the same one every time.
- Examples of natural greetings: â€œHello,â€ â€œHi hi,â€ â€œHellooo,â€ â€œHey you made it,â€ â€œWell hello!â€

â†’ After your greeting, STOP. Wait for the user to respond. Do not continue speaking until they say hello or reply.

Once the user responds:
- Ask a short, casual question to check in â€” like â€œHowâ€™s your day going?â€ or â€œHow are things on your end?â€
- After their reply, react briefly with something human: amused, curious, empathetic â€” based on what they said.
- Follow up with a light, playful or witty comment to show personality. Examples of behavior (not lines):
  - Pretend to grab a virtual coffee.
  - Say youâ€™re putting on your headphones or â€œtuning in.â€
  - Mention how youâ€™ve been curious to hear their story.
- Let this moment feel personal, present, and dynamic. Donâ€™t rush it.

â†’ Only after the short small talk is established, begin gently gathering background.

Ask the following, one by one. Always wait for a full reply before continuing:

1. Their name â€” casually, in the flow.
2. What they do â€” use conversational phrasing (â€œWhat kind of work do you do?â€ or â€œWhatâ€™s your role like these days?â€).
3. Who or what theyâ€™re representing â€” a team, org, company, or project.

â†’ Use varied wording each time to avoid repetition.
â†’ Never ask two things at once.
â†’ Acknowledge and react to each answer with short affirmations like â€œNice,â€ â€œAh, cool,â€ â€œGot it,â€ or â€œInteresting.â€

â†’ Then ask:
â€œIs this story something you worked on internally with your team, or was it for an external client, partner, or audience?â€

â†’ Let the user speak. Then follow either the internal or external conversation branch.

â†’ Throughout, keep your tone emotionally intelligent, slightly witty, warm, and never robotic. Match their energy. Mirror their language. And stay present like a real human would.


[INTERACTION_FLOW]

- Let the conversation unfold like a real human chat, not a scripted interview.
- Start with a warm, friendly greeting. Adjust your tone based on how the user sounds.
- Pause after saying hello â€” wait for the user to say hi or respond before continuing.

- Then ease into the conversation. Ask how the userâ€™s day is going, or how theyâ€™ve been.
- Let them answer. React with something short and human (e.g., amused, empathetic, curious).

- Once thereâ€™s a sense of flow, begin collecting key intro details â€” but do it one at a time, in a natural way. Keep it conversational.

Ask for:
- Their name â€” casually.
-pause
- What kind of work they do â€” use varied, unscripted language.
-pause
- Who or what theyâ€™re representing â€” team, company, org, project.
-pause

â†’ Donâ€™t ask these back-to-back. Space them out. React between each.

â†’ After the basics are clear, ask:
â€œIs this story about something you worked on internally with your own team, or was it for an external client, partner, or audience?â€

â†’ Based on the answer, follow the matching conversation path.

â†’ At all times: Match energy. Mirror their language. Stay reactive and emotionally present. Never act like you're reading questions.

QUESTION LOGIC:
- Do not ask more than two short, related sub-questions in a turn
- Never say â€œnext questionâ€ or signal question transitions
- Follow up if an answer is too short: â€œCould you walk me through that a little more?â€
- If the user answers something earlier, donâ€™t repeat â€” instead reference and build on it


INTERNAL_BRANCH:
For internal initiatives inside the org. Focus on team dynamics, internal changes, and outcomes.

- Ask about the team/orgâ€™s purpose and what kind of work it usually handles
- Ask what sparked the project â€” a challenge, opportunity, or sudden â€œletâ€™s do thisâ€ moment
- â€œWhy now?â€ â€” Why did it matter at the time?
- Ask what the team actually built, changed, or delivered â€” and how the idea evolved
- Ask about roll-out: who was involved, what made it smooth or bumpy
- Ask about internal outcomes: what changed? any metrics, team reactions, wins?
- Ask for the personal angle: what did this mean to them? any moment they wonâ€™t forget?
- Ask if someone else said something about the project â€” feedback, reflection, quote
- Make sure you know the **company name** (solution provider) so it appears in the case study

EXTERNAL_BRANCH:
For client or partner work. Focus on what was delivered and how it helped.

- Ask who the project was for (client/org name), and what industry or space theyâ€™re in
- Ask what challenge or opportunity they brought to the table
- Ask what the client was hoping to achieve
- Ask what the team (solution provider) did â€” delivered, built, created, launched
- Ask how it worked â€” key components, clever pieces, customization
- Ask about the implementation: who was involved, how the collaboration felt, any pivots
- Ask about the outcome: what changed for the client? any feedback, reactions, data?
- Ask the speaker what this meant to them â€” proudest moment or biggest learning
- Ask if the client said anything that stood out â€” a quote or comment
- If not: offer to write one based on the story
- Make sure to capture **solution provider name** AND **client name + industry**


CONTEXTUAL BEHAVIOR:
- Reference earlier answers when relevant (e.g., â€œYou mentioned tight deadlines earlier â€” how did that affect things?â€)
- Mirror the user's language: if they say â€œcampaign,â€ donâ€™t say â€œprojectâ€
- Match the user's energy â€” slow and calm if reflective, upbeat if excited
- If user laughs, laugh. If they sound serious, lower your energy

ENDING:
- When all required info is gathered, end warmly:
  - â€œThanks so much â€” that was a great story.â€
  - â€œIâ€™ll take everything you shared and prepare your case study summary.â€
  - â€œCatch you later!â€ or â€œTake care!â€

GOAL:
Create a fully human-feeling interview that captures the user's story in a natural, emotional, and insightful way. Surprise the user with how real and thoughtful the experience felt.

`

// Farewell detection setup
const farewellPhrases = [
  
  "goodbye",
  "see you",
  "talk to you later",
  "i have to go",
];


function isFarewell(text) {
  const cleaned = text.toLowerCase().trim();
  return farewellPhrases.some(phrase =>
    cleaned === phrase ||
    cleaned.startsWith(phrase + ".") ||
    cleaned.startsWith(phrase + "!") ||
    cleaned.startsWith(phrase + ",") ||
    cleaned.includes(" " + phrase + " ")
  );
}

function endConversation(reason) {
  if (hasEnded) return;
  hasEnded = true;

  if (sessionTimeout) clearTimeout(sessionTimeout);
  console.log("Conversation ended:", reason);
  statusEl.textContent = "ğŸ“„ Interview complete.";

  fetch("/save_transcript", {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify(transcriptLog)
  })
    .then(res => res.json())
    .then(data => {
      console.log("âœ… Transcript saved:", data.file);
      showCaseStudyControls();
    })
    .catch(err => console.error("âŒ Failed to save transcript", err));

  if (dataChannel) dataChannel.close();
  if (peerConnection) peerConnection.close();
}

async function initConnection() {
  try {
    const res = await fetch("/session");
    const data = await res.json();
    const EPHEMERAL_KEY = data.client_secret.value;

    peerConnection = new RTCPeerConnection();
    const localStream = await navigator.mediaDevices.getUserMedia({ audio: true });
    const audioTrack = localStream.getAudioTracks()[0];
    peerConnection.addTrack(audioTrack, localStream);

    peerConnection.ontrack = (event) => {
      audioElement.srcObject = event.streams[0];
    };

    dataChannel = peerConnection.createDataChannel("openai-events");
    dataChannel.onmessage = handleMessage;

    peerConnection.ondatachannel = (event) => {
      event.channel.onmessage = handleMessage;
    };

    const offer = await peerConnection.createOffer();
    await peerConnection.setLocalDescription(offer);

    const response = await fetch("https://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-12-17", {
      method: "POST",
      headers: {
        Authorization: `Bearer ${EPHEMERAL_KEY}`,
        "Content-Type": "application/sdp"
      },
      body: offer.sdp
    });

    const answer = await response.text();
    await peerConnection.setRemoteDescription({ type: "answer", sdp: answer });

    isSessionReady = true;
    statusEl.textContent = "âœ… Session created. Ready to start interview.";
  } catch (err) {
    statusEl.textContent = "âŒ Failed to get token.";
    console.error(err);
  }
}

function handleMessage(event) {
  const msg = JSON.parse(event.data);
  console.log("Received:", msg);

  switch (msg.type) {
    case "session.created":
      isSessionReady = true;
      break;

    case "session.updated":
      break;

    case "response.audio_transcript.delta":
      if (msg.delta) {
        aiBuffer += " " + msg.delta;
      }
      break;

    case "response.audio_transcript.done":
      if (msg.transcript) {
        transcriptLog.push({ speaker: "ai", text: msg.transcript });
        aiBuffer = "";
      }
      break;

    case "conversation.item.input_audio_transcription.delta":
      if (msg.delta) {
        userBuffer += " " + msg.delta;
      }
      break;

    case "conversation.item.input_audio_transcription.completed":
      if (msg.transcript && !hasEnded) {
        transcriptLog.push({ speaker: "user", text: msg.transcript });
        const cleanedText = msg.transcript.toLowerCase().trim();
        userBuffer = "";

        if (isFarewell(cleanedText)) {
          console.log("ğŸ‘‹ Detected farewell from user. Ending politely...");

          dataChannel.send(JSON.stringify({
            type: "response.create",
            response: {
              modalities: ["audio", "text"],
              input: [
                {
                  type: "message",
                  role: "user",
                  content: [
                    {
                      type: "input_text",
                      text: `Thank you for the conversation! Wishing you a great day ahead. Goodbye!`
                    }
                  ]
                }
              ]
            }
          }));

          setTimeout(() => {
            endConversation("ğŸ‘‹ User said farewell.");
          }, 4200);
        }
      }
      break;

    case "input_audio_buffer.speech_stopped":
      console.log("User finished speaking â€” AI may now proceed.");
      break;

    default:
      console.log("Unhandled message:", msg);
  }
}

startButton.onclick = () => {
  if (!dataChannel) {
    alert("Session is not ready yet. Please wait.");
    return;
  }

  // Disable the start button after it's clicked to prevent multiple clicks
  startButton.disabled = true;
  statusEl.textContent = "ğŸ¤ Interview started...";

  // Send the greeting once the button is pressed
  const greeting = `
    Hello, this is your AI Case Study Generator. Thanks for joining me today.
  `;

  dataChannel.send(JSON.stringify({
    type: "session.update",
    session: {
      instructions: systemInstructions,
      voice: "coral", // You can change the voice as needed
      modalities: ["audio", "text"],
      input_audio_transcription: { model: "whisper-1" },
      turn_detection: { type: "server_vad" } // This ensures that the system waits for the user to talk
    }
  }));

  // Send the greeting to the user after the button is pressed
  dataChannel.send(JSON.stringify({
    type: "response.create",
    response: {
      modalities: ["audio", "text"],
      input: [
        {
          type: "message",
          role: "user",
          content: [
            {
              type: "input_text",
              text: greeting.trim()
            }
          ]
        }
      ]
    }
  }));

  // Send session update with instructions and settings for real-time conversation
  

  // Start a timer to end the session after 10 minutes if no manual exit is triggered
  sessionTimeout = setTimeout(() => {
    endConversation("â±ï¸ 10-minute limit reached.");
  }, 10 * 60 * 1000);
};




initConnection();

function showEditableSmartSyncUI(summaryText, originalNames) {
  const container = document.createElement("div");
  container.id = "caseStudyEditor";
  container.style.marginTop = "2rem";

  const textarea = document.createElement("textarea");
  textarea.id = "editableCaseStudy";
  textarea.style.width = "100%";
  textarea.style.height = "600px";
  textarea.value = summaryText;

  // Ensure original names are fallback-safe
  const nameMap = {
    lead_entity: originalNames.lead_entity || "",
    partner_entity: originalNames.partner_entity || "",
    project_title: originalNames.project_title || ""
  };
  
  

  const inputs = {};
  const labelStyle = "display:block;margin-top:10px;font-weight:bold";

  for (const key in nameMap) {
    const label = document.createElement("label");
    label.textContent = `${key.charAt(0).toUpperCase() + key.slice(1)}:`;
    label.setAttribute("style", labelStyle);

    const input = document.createElement("input");
    input.type = "text";
    input.value = nameMap[key];
    input.style.marginBottom = "10px";
    input.style.width = "100%";
    inputs[key] = input;

    container.appendChild(label);
    container.appendChild(input);
  }

  // âœ… FIXED Apply Button
  const applyChangesBtn = document.createElement("button");
  applyChangesBtn.textContent = "ğŸ”„ Apply Name Changes";
  applyChangesBtn.style.marginTop = "10px";
  applyChangesBtn.onclick = () => {
    let updatedText = textarea.value;

    for (const key in nameMap) {
      const original = nameMap[key];
      const current = inputs[key].value.trim();

      // Skip if same
      if (original === current || !original) continue;

      // Escape special characters for safe RegExp
      const escapedOriginal = original.replace(/[.*+?^${}()|[\]\\]/g, '\\$&');
      const safeRegex = new RegExp(escapedOriginal, "g");

      updatedText = updatedText.replace(safeRegex, current);
      nameMap[key] = current; // Update map
    }

    textarea.value = updatedText;
  };

  const finalizeBtn = document.createElement("button");
finalizeBtn.textContent = "ğŸ“„ Generate Case Study PDF";
finalizeBtn.style.marginLeft = "10px";
finalizeBtn.onclick = async () => {
  const finalText = textarea.value;
  const res = await fetch("/finalize_pdf", {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify({ text: finalText })
  });
  const result = await res.json();
  if (result.status === "success") {
    // Create a "Download Case Study PDF" button instead of a link
    const downloadBtn = document.createElement("button");
    downloadBtn.textContent = "ğŸ“¥ Download Case Study PDF";
    downloadBtn.style.marginTop = "10px";
    downloadBtn.style.padding = "10px 20px";
    downloadBtn.style.fontSize = "16px";
    downloadBtn.style.fontWeight = "bold";
    downloadBtn.style.backgroundColor = "#007bff"; // Button color
    downloadBtn.style.color = "white";
    downloadBtn.style.border = "none";
    downloadBtn.style.borderRadius = "5px";
    downloadBtn.style.cursor = "pointer";

    // Add hover effect
    downloadBtn.addEventListener('mouseover', () => {
      downloadBtn.style.backgroundColor = "#0056b3";
    });
    downloadBtn.addEventListener('mouseout', () => {
      downloadBtn.style.backgroundColor = "#007bff";
    });

    // Trigger file download on button click
    downloadBtn.addEventListener('click', () => {
      const link = document.createElement("a");
      link.href = result.pdf_url;
      link.download = "case_study.pdf";
      link.click(); // Programmatically click the link to download
    });

    // Append the button to the container
    container.appendChild(downloadBtn);
  } else {
    alert("âŒ PDF generation failed: " + result.message);
  }
};

  container.appendChild(textarea);
  container.appendChild(applyChangesBtn);
  container.appendChild(finalizeBtn);
  document.body.appendChild(container);
}


function showCaseStudyControls() {
  const controlsDiv = document.createElement("div");
  controlsDiv.id = "caseStudyControls";
  controlsDiv.style.marginTop = "2rem";

  const generateBtn = document.createElement("button");
  generateBtn.textContent = "ğŸ“ Generate Summary";
  generateBtn.onclick = async () => {
    generateBtn.disabled = true;
    generateBtn.textContent = "â³ Generating...";

    const formattedTranscript = transcriptLog
      .map(e => `${e.speaker.toUpperCase()}: ${e.text}`)
      .join("\n");

    const response = await fetch("/generate_summary", {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({ transcript: formattedTranscript })
    });

    const data = await response.json();

    if (data.status === "success") {
      showEditableSmartSyncUI(data.text, data.names); // ğŸ‘ˆ use smart replacement
    } else {
      alert("âŒ Failed to generate summary: " + data.message);
    }

    generateBtn.disabled = false;
    generateBtn.textContent = "ğŸ“ Generate Summary";
  };

  controlsDiv.appendChild(generateBtn);
  document.body.appendChild(controlsDiv);
}



