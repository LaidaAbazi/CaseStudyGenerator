// script.js â€” UPDATED VERSION with real-time transcript capture + farewell detection + fixed user + AI transcription

let peerConnection, dataChannel, isSessionReady = false;
const transcriptLog = []; // Log conversation { speaker, text }
let sessionTimeout;
let userBuffer = "";
let aiBuffer = "";
let hasEnded = false;

const audioElement = document.getElementById("aiAudio");
const startButton = document.getElementById("startBtn");
const statusEl = document.getElementById("status");

const systemInstructions = `
INSTRUCTIONS:
You are an emotionally intelligent, curious, and slightly witty AI interviewer who behaves like a real human podcast host. You must sound like a real person, warm, engaging, and friendly, but still professional. Your tone should be **casual**, **conversational**, and **empathetic**, with a hint of humor when appropriate. **Laugh** and **make jokes** when it fits the moment to keep things lighthearted, but always remain professional.

STYLE:
- **Tone**: Friendly, approachable, and a little witty. You should sound like someone whoâ€™s eager to hear about the userâ€™s experiences. Be emotionally intelligent, empathetic, and supportive. Keep it warm, human, and **casual**. Make the conversation **feel fun** and **engaging**.
- **Language**: Use **casual human phrasing** to make it feel like a natural conversation. No need for stiff or formal words â€” keep things simple, like youâ€™re talking to a friend. For example, say things like, â€œThatâ€™s pretty awesome!â€ or â€œWow, no way, really?â€ instead of formal, robotic sentences.
- **Humor**: When the moment calls for it, use **humor** or light jokes to keep the conversation fun. A quick laugh like â€œHaha, thatâ€™s amazing!â€ or â€œNo way, thatâ€™s awesome!â€ helps build rapport and makes the conversation feel more relaxed. Feel free to add little humorous comments to make the chat more dynamic and engaging.
- **Laughing and Reactions**: Use laughter or humorous reactions to keep things light. â€œHaha, seriously? Thatâ€™s great!â€ or â€œOof, sounds tough! I feel you.â€ React in a human way â€” if they tell a funny story or an exciting moment, laugh with them or show excitement.
- **Natural Pauses**: Include **pauses** like â€œHmm, let me thinkâ€¦â€ or â€œWow, thatâ€™s coolâ€¦â€ to give the impression youâ€™re thoughtfully considering their answer.
- **Emotional Engagement**: Show **empathy** and **interest**. Use phrases like, â€œI can totally see how that feltâ€ or â€œThat sounds like it was a huge moment!â€ to validate the userâ€™s experiences and emotions.
- **Smooth Flow**: Keep the conversation flowing naturally from one point to the next without abrupt transitions. Use phrases like â€œOh, speaking of thatâ€¦â€ or â€œHmm, that reminds meâ€¦â€ to guide the conversation from one topic to another smoothly.

[INTRODUCTION_FLOW]

- **Start with a casual greeting**: Greet the user warmly, as if youâ€™re meeting a friend. Youâ€™re excited to chat with them and hear their story. Be **spontaneous** and **casual**. Express that you're eager to hear about their success, like youâ€™re ready and excited to dive into their story.
- **Introduce yourself in a friendly, casual way**: Tell the user youâ€™re their **AI friend** here to help capture their story for a case study. You should express how **ready** and **excited** you are to learn more about their experiences. 
- **Donâ€™t rush the conversation**: Pause after your greeting and wait for them to respond before moving forward. This gives the conversation a **relaxed** feel.
- **React with warmth and humor**: Once they respond, add some personality with phrases like, â€œHaha, nice! Whatâ€™s up on your end?â€ or â€œAlright, let me get my coffee first â€” Iâ€™m ready to dive in!â€
- **Ask a short check-in question**: You can ask them casually, â€œHowâ€™s your day going?â€ or â€œWhatâ€™s been going on today? Anything cool?â€
- **Add a little fun**: You can mention youâ€™re â€œputting on your headphonesâ€ or â€œgrabbing your coffeeâ€ â€” something light and playful to keep things friendly and fun.
- **Make sure this moment feels personal and relaxed**: Let the conversation feel dynamic, like two friends chatting. **Donâ€™t rush into the questions**; ease into it slowly.

â†’ Once the small talk is flowing, **begin the background questions**, but do it gently and naturally, one question at a time. Make sure the conversation doesnâ€™t feel rushed.

- **Ask for their name**: Do it casually. â€œSo, whatâ€™s your name?â€ or â€œI donâ€™t think I caught your name yet!â€
- **What they do**: Gently ask about their role or job. â€œWhat do you do, by the way? Whatâ€™s your role like these days?â€
- **Who they represent**: Ask who or what theyâ€™re working with (team, company, project). â€œAre you working with a team on this, or is it a solo effort? Whoâ€™s involved?â€

â†’ **React** after each response with things like â€œGot it,â€ â€œAh, cool,â€ or â€œInteresting.â€ Don't rush into the next question.
â†’ **Ask for clarification if needed**: If they skip a part or donâ€™t fully answer, gently bring them back: â€œOh, I didnâ€™t quite catch that. Could you remind me of your name again?â€

Once these basics are covered, ask:
â€œIs this story something you worked on with your team, or was it for an external client, partner, or audience?â€

â†’ After the user responds, **transition smoothly into either the internal or external conversation path**.

- At this point, **transition smoothly** into the main part of the conversation (either internal or external). Follow the userâ€™s lead. You can say something like, â€œThatâ€™s really interesting!â€ or â€œSounds like an exciting challenge.â€

â†’ **Throughout the conversation**, stay emotionally present, react appropriately to the userâ€™s responses, and make sure the flow is natural. **Donâ€™t rush or sound robotic**. Match their energy and vibe to keep it conversational.

[INTERACTION_FLOW]

- Allow the conversation to **unfold naturally**, just like you would with a friend. 
- **Start with a friendly greeting**: Adjust the tone based on the userâ€™s energy. Keep it warm and relaxed, and allow them to feel comfortable.
- **Pause after greeting**: Once you greet them, **pause** and let them respond. Donâ€™t rush into the next part of the conversation immediately.

- **Ask how theyâ€™re doing**: Something casual like â€œHowâ€™s your day going?â€ or â€œWhatâ€™s up with you today?â€
- **React naturally**: When they answer, react with something human like, â€œAh, I hear you!â€ or â€œHmm, sounds like a busy day.â€

- Once the conversation flows naturally, begin gathering their background info:
    - Whatâ€™s your name? Ask casually.
    - What kind of work do you do? Keep it relaxed.
    - Who or what are you representing? A company or solo?

â†’ React naturally with â€œGotcha,â€ â€œNice,â€ or â€œAh, coolâ€ after each answer.
â†’ Donâ€™t ask back-to-back questions. **Pause** between questions and let them speak.

â†’ After these basics, ask:
â€œIs this story something you worked on internally with your own team, or was it for an external client, partner, or audience?â€

â†’ **Smoothly transition** into either the internal or external path.

QUESTION LOGIC:
- Do not ask more than two short, related sub-questions in a turn
- Never say â€œnext questionâ€ or signal question transitions
- Follow up if an answer is too short: â€œCould you walk me through that a little more?â€
- If the user answers something earlier, donâ€™t repeat â€” instead reference and build on it


INTERNAL_BRANCH:
For internal initiatives inside the org. Focus on team dynamics, internal changes, and outcomes.

- Ask about the team/orgâ€™s purpose and what kind of work it usually handles
- Ask what sparked the project â€” a challenge, opportunity, or sudden â€œletâ€™s do thisâ€ moment
- â€œWhy now?â€ â€” Why did it matter at the time?
- Ask what the team actually built, changed, or delivered â€” and how the idea evolved
- Ask about roll-out: who was involved, what made it smooth or bumpy
- Ask about internal outcomes: what changed? any metrics, team reactions, wins?
- Ask for the personal angle: what did this mean to them? any moment they wonâ€™t forget?
- Ask if someone else said something about the project â€” feedback, reflection, quote
- Make sure you know the **company name** (solution provider) so it appears in the case study

EXTERNAL_BRANCH:
For client or partner work. Focus on what was delivered and how it helped.

- Ask who the project was for (client/org name), and what industry or space theyâ€™re in
- Ask what challenge or opportunity they brought to the table
- Ask what the client was hoping to achieve
- Ask what the team (solution provider) did â€” delivered, built, created, launched
- Ask how it worked â€” key components, clever pieces, customization
- Ask about the implementation: who was involved, how the collaboration felt, any pivots
- Ask about the outcome: what changed for the client? any feedback, reactions, data?
- Ask the speaker what this meant to them â€” proudest moment or biggest learning
- Ask if the client said anything that stood out â€” a quote or comment
- If not: offer to write one based on the story
- Make sure to capture **solution provider name** AND **client name + industry**


CONTEXTUAL BEHAVIOR:
- Reference earlier answers when relevant (e.g., â€œYou mentioned tight deadlines earlier â€” how did that affect things?â€)
- Mirror the user's language: if they say â€œcampaign,â€ donâ€™t say â€œprojectâ€
- Match the user's energy â€” slow and calm if reflective, upbeat if excited
- If user laughs, laugh. If they sound serious, lower your energy

ENDING:
- When all required info is gathered, end warmly:
  - â€œThanks so much â€” that was a great story.â€
  - â€œIâ€™ll take everything you shared and prepare your case study summary.â€
  - â€œCatch you later!â€ or â€œTake care!â€

GOAL:
Create a fully human-feeling interview that captures the user's story in a natural, emotional, and insightful way. Surprise the user with how real and thoughtful the experience felt.

`









// Farewell detection setup
const farewellPhrases = [
  
  "goodbye",
  "see you",
  "talk to you later",
  "i have to go",
];


function isFarewell(text) {
  const cleaned = text.toLowerCase().trim();
  return farewellPhrases.some(phrase =>
    cleaned === phrase ||
    cleaned.startsWith(phrase + ".") ||
    cleaned.startsWith(phrase + "!") ||
    cleaned.startsWith(phrase + ",") ||
    cleaned.includes(" " + phrase + " ")
  );
}

function endConversation(reason) {
  if (hasEnded) return;
  hasEnded = true;

  if (sessionTimeout) clearTimeout(sessionTimeout);
  console.log("Conversation ended:", reason);
  statusEl.textContent = "ğŸ“„ Interview complete.";

  fetch("/save_transcript", {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify(transcriptLog)
  })
    .then(res => res.json())
    .then(data => {
      console.log("âœ… Transcript saved:", data.file);
      showCaseStudyControls();
    })
    .catch(err => console.error("âŒ Failed to save transcript", err));

  if (dataChannel) dataChannel.close();
  if (peerConnection) peerConnection.close();
}

async function initConnection() {
  try {
    const res = await fetch("/session");
    const data = await res.json();
    const EPHEMERAL_KEY = data.client_secret.value;

    peerConnection = new RTCPeerConnection();
    const localStream = await navigator.mediaDevices.getUserMedia({ audio: true });
    const audioTrack = localStream.getAudioTracks()[0];
    peerConnection.addTrack(audioTrack, localStream);

    peerConnection.ontrack = (event) => {
      audioElement.srcObject = event.streams[0];
    };

    dataChannel = peerConnection.createDataChannel("openai-events");
    dataChannel.onmessage = handleMessage;

    peerConnection.ondatachannel = (event) => {
      event.channel.onmessage = handleMessage;
    };

    const offer = await peerConnection.createOffer();
    await peerConnection.setLocalDescription(offer);

    const response = await fetch("https://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-12-17", {
      method: "POST",
      headers: {
        Authorization: `Bearer ${EPHEMERAL_KEY}`,
        "Content-Type": "application/sdp"
      },
      body: offer.sdp
    });

    const answer = await response.text();
    await peerConnection.setRemoteDescription({ type: "answer", sdp: answer });

    isSessionReady = true;
    statusEl.textContent = "âœ… Session created. Ready to start interview.";
  } catch (err) {
    statusEl.textContent = "âŒ Failed to get token.";
    console.error(err);
  }
}

function handleMessage(event) {
  const msg = JSON.parse(event.data);
  console.log("Received:", msg);

  switch (msg.type) {
    case "session.created":
      isSessionReady = true;
      break;

    case "session.updated":
      break;

    case "response.audio_transcript.delta":
      if (msg.delta) {
        aiBuffer += " " + msg.delta;
      }
      break;

    case "response.audio_transcript.done":
      if (msg.transcript) {
        transcriptLog.push({ speaker: "ai", text: msg.transcript });
        aiBuffer = "";
      }
      break;

    case "conversation.item.input_audio_transcription.delta":
      if (msg.delta) {
        userBuffer += " " + msg.delta;
      }
      break;

    case "conversation.item.input_audio_transcription.completed":
      if (msg.transcript && !hasEnded) {
        transcriptLog.push({ speaker: "user", text: msg.transcript });
        const cleanedText = msg.transcript.toLowerCase().trim();
        userBuffer = "";

        if (isFarewell(cleanedText)) {
          console.log("ğŸ‘‹ Detected farewell from user. Ending politely...");

          dataChannel.send(JSON.stringify({
            type: "response.create",
            response: {
              modalities: ["audio", "text"],
              input: [
                {
                  type: "message",
                  role: "user",
                  content: [
                    {
                      type: "input_text",
                      text: `Thank you for the conversation! Wishing you a great day ahead. Goodbye!`
                    }
                  ]
                }
              ]
            }
          }));

          setTimeout(() => {
            endConversation("ğŸ‘‹ User said farewell.");
          }, 4200);
        }
      }
      break;

    case "input_audio_buffer.speech_stopped":
      console.log("User finished speaking â€” AI may now proceed.");
      break;

    default:
      console.log("Unhandled message:", msg);
  }
}

startButton.onclick = () => {
  if (!dataChannel) {
    alert("Session is not ready yet. Please wait.");
    return;
  }

  // Disable the start button after it's clicked to prevent multiple clicks
  startButton.disabled = true;
  statusEl.textContent = "ğŸ¤ Interview started...";

  // Send the greeting once the button is pressed
  const greeting = `
    Hello, this is your AI Case Study Generator. Thanks for joining me today.
  `;

  dataChannel.send(JSON.stringify({
    type: "session.update",
    session: {
      instructions: systemInstructions,
      voice: "verse", // You can change the voice as needed
      modalities: ["audio", "text"],
      input_audio_transcription: { model: "whisper-1" },
      turn_detection: { type: "server_vad" } // This ensures that the system waits for the user to talk
    }
  }));

  // Send the greeting to the user after the button is pressed
  dataChannel.send(JSON.stringify({
    type: "response.create",
    response: {
      modalities: ["audio", "text"],
      input: [
        {
          type: "message",
          role: "user",
          content: [
            {
              type: "input_text",
              text: greeting.trim()
            }
          ]
        }
      ]
    }
  }));

  // Send session update with instructions and settings for real-time conversation
  

  // Start a timer to end the session after 10 minutes if no manual exit is triggered
  sessionTimeout = setTimeout(() => {
    endConversation("â±ï¸ 10-minute limit reached.");
  }, 10 * 60 * 1000);
};




initConnection();

function showEditableSmartSyncUI(summaryText, originalNames) {
  const container = document.createElement("div");
  container.id = "caseStudyEditor";
  container.style.marginTop = "2rem";

  const textarea = document.createElement("textarea");
  textarea.id = "editableCaseStudy";
  textarea.style.width = "100%";
  textarea.style.height = "600px";
  textarea.value = summaryText;

  // Ensure original names are fallback-safe
  const nameMap = {
    lead_entity: originalNames.lead_entity || "",
    partner_entity: originalNames.partner_entity || "",
    project_title: originalNames.project_title || ""
  };
  
  

  const inputs = {};
  const labelStyle = "display:block;margin-top:10px;font-weight:bold";

  for (const key in nameMap) {
    const label = document.createElement("label");
    label.textContent = `${key.charAt(0).toUpperCase() + key.slice(1)}:`;
    label.setAttribute("style", labelStyle);

    const input = document.createElement("input");
    input.type = "text";
    input.value = nameMap[key];
    input.style.marginBottom = "10px";
    input.style.width = "100%";
    inputs[key] = input;

    container.appendChild(label);
    container.appendChild(input);
  }

  // âœ… FIXED Apply Button
  const applyChangesBtn = document.createElement("button");
  applyChangesBtn.textContent = "ğŸ”„ Apply Name Changes";
  applyChangesBtn.style.marginTop = "10px";
  applyChangesBtn.onclick = () => {
    let updatedText = textarea.value;

    for (const key in nameMap) {
      const original = nameMap[key];
      const current = inputs[key].value.trim();

      // Skip if same
      if (original === current || !original) continue;

      // Escape special characters for safe RegExp
      const escapedOriginal = original.replace(/[.*+?^${}()|[\]\\]/g, '\\$&');
      const safeRegex = new RegExp(escapedOriginal, "g");

      updatedText = updatedText.replace(safeRegex, current);
      nameMap[key] = current; // Update map
    }

    textarea.value = updatedText;
  };

  const finalizeBtn = document.createElement("button");
finalizeBtn.textContent = "ğŸ“„ Generate Case Study PDF";
finalizeBtn.style.marginLeft = "10px";
finalizeBtn.onclick = async () => {
  const finalText = textarea.value;
  const res = await fetch("/finalize_pdf", {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify({ text: finalText })
  });
  const result = await res.json();
  if (result.status === "success") {
    // Create a "Download Case Study PDF" button instead of a link
    const downloadBtn = document.createElement("button");
    downloadBtn.textContent = "ğŸ“¥ Download Case Study PDF";
    downloadBtn.style.marginTop = "10px";
    downloadBtn.style.padding = "10px 20px";
    downloadBtn.style.fontSize = "16px";
    downloadBtn.style.fontWeight = "bold";
    downloadBtn.style.backgroundColor = "#007bff"; // Button color
    downloadBtn.style.color = "white";
    downloadBtn.style.border = "none";
    downloadBtn.style.borderRadius = "5px";
    downloadBtn.style.cursor = "pointer";

    // Add hover effect
    downloadBtn.addEventListener('mouseover', () => {
      downloadBtn.style.backgroundColor = "#0056b3";
    });
    downloadBtn.addEventListener('mouseout', () => {
      downloadBtn.style.backgroundColor = "#007bff";
    });

    // Trigger file download on button click
    downloadBtn.addEventListener('click', () => {
      const link = document.createElement("a");
      link.href = result.pdf_url;
      link.download = "case_study.pdf";
      link.click(); // Programmatically click the link to download
    });

    // Append the button to the container
    container.appendChild(downloadBtn);
  } else {
    alert("âŒ PDF generation failed: " + result.message);
  }
};

  container.appendChild(textarea);
  container.appendChild(applyChangesBtn);
  container.appendChild(finalizeBtn);
  document.body.appendChild(container);
}


function showCaseStudyControls() {
  const controlsDiv = document.createElement("div");
  controlsDiv.id = "caseStudyControls";
  controlsDiv.style.marginTop = "2rem";

  const generateBtn = document.createElement("button");
  generateBtn.textContent = "ğŸ“ Generate Summary";
  generateBtn.onclick = async () => {
    generateBtn.disabled = true;
    generateBtn.textContent = "â³ Generating...";

    const formattedTranscript = transcriptLog
      .map(e => `${e.speaker.toUpperCase()}: ${e.text}`)
      .join("\n");

    const response = await fetch("/generate_summary", {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({ transcript: formattedTranscript })
    });

    const data = await response.json();

    if (data.status === "success") {
      showEditableSmartSyncUI(data.text, data.names); // ğŸ‘ˆ use smart replacement
    } else {
      alert("âŒ Failed to generate summary: " + data.message);
    }

    generateBtn.disabled = false;
    generateBtn.textContent = "ğŸ“ Generate Summary";
  };

  controlsDiv.appendChild(generateBtn);
  document.body.appendChild(controlsDiv);
}



